---
layout: single
title: "ML 3-1. 사이킷런 라이브러리 - 퍼셉트론"
use_math : True
categories: python_machine_learning
tags: machine_learning
toc: true
toc_sticky: true
---


## 3. Scikit Learn


### 3-1. 사이킷런 라이브러리 - 퍼셉트론

---

퍼셉트론 모델을 훈련하는 것으로 사이킷런 라이브러리를 시작한다.  

* 붓꽃 데이터셋을 load한다. (scikit-learn 라이브러리에 포함되어 있음)


```python
from sklearn import datasets
import numpy as np

iris = datasets.load_iris()
X = iris.data[:,[2,3]]
y = iris.target
print('클래스 레이블:', np.unique(y))
```

    클래스 레이블: [0 1 2]


* 데이터셋을 train set과 test set으로 분리한다.


```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1, stratify = y)

print('y의 레이블 카운트:', np.bincount(y), 'y_train의 레이블 카운트:', np.bincount(y_train), \
 'y_test의 레이블 카운트:', np.bincount(y_test))
```

    y의 레이블 카운트: [50 50 50] y_train의 레이블 카운트: [35 35 35] y_test의 레이블 카운트: [15 15 15]


`train_test_split` : 분할 전 데이터셋을 미리 섞는 역할<br/>  
`stratify` : 계층화(stratification)기능, 훈련 세트와 테스트 세트의 클래스 레이블 비율을 입력 데이터셋과 동일하게 만듬<br/>  
`bincount` : numpy함수, 배열에 있는 고유값의 등장 횟수를 셈<br/><br/>  


* 사이킷런의 preprocessing 모듈의 StandardScaler 클래스를 사용해 특성 표준화


```python
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
sc.fit(X_train)
X_train_std = sc.transform(X_train)
X_test_std = sc.transform(X_test)
```

`fit` : 훈련 세트의 각 특성 차원(column)마다 $\mu$(샘플 평균)과 $\sigma$(표준 편차) 계산<br/>  
`transform` : 계산된 $\mu$와 $\sigma$를 사용해 훈련 세트 표준화<br/>  
train, test 샘플이 같은 비율로 이동되도록 동일한 $\mu$와 $\sigma$ 사용  

* 퍼셉트론 모델 훈련  

Scikit-learn의 알고리즘은 OvR(One-versus-Rest)방식을 사용하여 multiclass classification을 지원한다.  

        OvR: 1~10까지의 클래스가 있을 때, 각각의 숫자 하나만 True로, 나머지 숫자를 전부 False로 놓고 숫자 하나를 분류하는 이진 분류기를 10개 만든다. 이 10개의 분류기에 샘플을 넣고 가장 높은 점수가 나온 클래스를 선택하는 방식이다.  
        
붓꽃 데이터의 클래스는 3개이므로, 다중 분류를 사용한다.


```python
from sklearn.linear_model import Perceptron

#훈련
ppn = Perceptron(max_iter = 40, eta0 = 0.1, tol = 1e-3, random_state = 1)
ppn.fit(X_train_std, y_train)

#예측
y_pred = ppn.predict(X_test_std)
print('잘못 분류된 샘플 개수: %d' %(y_test != y_pred).sum())

```

    잘못 분류된 샘플 개수: 1


테스트 세트에 대한 분류 오차는 약 2.2%이다.(1/45)  

사이킷런 라이브러리는 metrics 모듈 아래에 성능 지표를 구현한다.


```python
from sklearn.metrics import accuracy_score

print('정확도: %.3f' %accuracy_score(y_test,y_pred))

print('정확도: %.3f' %ppn.score(X_test_std, y_test))
```

    정확도: 0.978
    정확도: 0.978


`accuracy_score` : 분류 정확도 측정<br/>  
`score` : predict메서드와 accuracy_score메서드를 연결해 정확도 계산<br/><br/>  

* 퍼셉트론 모델의 결정 경계(decision_regions) 시각화


```python
from matplotlib.colors import ListedColormap
import matplotlib.pyplot as plt

def plot_decision_regions(X, y, classifier, test_idx = None, resolution = 0.02):

  # 마커와 컬러맵 설정
  markers = ('s', 'x', 'o', '^', 'v') # 사각형, 곱셈 기호, 원, 삼각형, 뒤집힌 삼각형
  colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
  cmap = ListedColormap(colors[:len(np.unique(y))]) # unique: numpy함수로, 고유값 반환

  # 결정 경계(Decision Boundary) 그리기
  x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
  x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1

  xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), \
                          np.arange(x2_min, x2_max, resolution))

  Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T) 
  #ravel: 1차원으로 만들어주는 numpy 함수
  Z = Z.reshape(xx1.shape)

  plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap) 
  #contourf: python함수, 2차원 등고선 플롯/ alpha: 투명도/ cmap: Colormap, 레벨 값을 색에 매핑 
  plt.xlim(xx1.min(), xx1.max())
  plt.ylim(xx2.min(), xx2.max())

  #산점도 그리기
  for idx, cl in enumerate(np.unique(y)):
    plt.scatter(x=X[y == cl, 0],y=X[y == cl, 1], alpha=0.8, c=colors[idx], \
      marker=markers[idx],label=cl, edgecolor = 'black')

  #테스트 샘플 부각
  if test_idx:
    X_test, y_test = X[test_idx, :], y[test_idx]
    plt.scatter(X_test[:, 0],X_test[:, 1], alpha=1.0, c='None', marker='o', \
      label='test set',linewidth = 1, s = 100, edgecolor = 'black')

X_combined_std = np.vstack((X_train_std, X_test_std)) #vertical stack
y_combined = np.hstack((y_train, y_test)) #horizontal stack
plot_decision_regions(X = X_combined_std, y = y_combined, classifier = ppn, test_idx = range(105,150))
plt.xlabel('petal length [standardized]')
plt.ylabel('petal width [standardized]')
plt.legend(loc = 'upper left')
plt.tight_layout()
plt.show()
```

![3-1 ScikitLearnPerceptron_13_1](https://user-images.githubusercontent.com/73334159/167627269-f1c1d885-cf9d-4624-aebb-9e0ae3b072e3.png)
    


완벽하게 분류되지 못한 모습을 볼 수 있다.  
퍼셉트론 알고리즘은 선형적으로 구분되지 않는 데이터셋에서 수렴할 수 없다. 

----
